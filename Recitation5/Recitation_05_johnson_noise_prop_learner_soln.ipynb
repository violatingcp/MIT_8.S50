{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "<hr style=\"height: 1px;\">\n",
    "<i>This code was authored by the 8.S50x Course Team, Copyright 2021 MIT All Rights Reserved.</i>\n",
    "<hr style=\"height: 1px;\">\n",
    "<br>\n",
    "\n",
    "# RECITATION 5: Johnson Noise\n",
    "\n",
    "<br>\n",
    "<!--end-block--> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## 5.0 Overview of Learning Objectives\n",
    "\n",
    "In this recitation we will explore the following objectives:\n",
    "\n",
    "- fill in information\n",
    "\n",
    "<br>\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## 5.1 Fitting Exercise 1\n",
    "\n",
    "Now, we are going to see how this applies to fitting. Let us first generate some data randomly from from the model $y=2x$.\n",
    "\n",
    "Let us suppose that we have two measurements that we need to add together, let's say we have $a_1 = 5 \\pm 3$ and $a_2 = 6 \\pm 4$. We want to estimate the uncertainty on \n",
    "\n",
    "$$f(a_1, a_2) = a_1 + a_2$$\n",
    "\n",
    "Using our error propogation formulas, we have\n",
    "\n",
    "$f(a_1, a_2) =  11 \\pm 5$\n",
    "\n",
    "However, we can use numpy to do this error propogation really easily. Let's see this below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "Run the cells below to define the function <code>f()</code>, which gives $f(a_{1},a_{2})$, and <code>p_histogram()</code>, which returns the counts and bin centers of a histogram for a sample of data.\n",
    "\n",
    "<!--\n",
    "#solution\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "\n",
    "def f(a_1, a_2):\n",
    "    return a_1 + a_2\n",
    "\n",
    "def p_histogram(samples, bins = 10, density = True):\n",
    "    counts, bin_edges = np.histogram(samples, bins = bins, density = density)\n",
    "    bin_centers = 0.5*(bin_edges[:-1]+bin_edges[1:])\n",
    "    return counts, bin_centers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:#BA2220\">>>>EXERCISE</span>\n",
    "\n",
    "Now we will use the definitions above to determine the mean and stdev for the sum of two samples of data, and compare to the expected values.\n",
    "\n",
    "Get two sets of random samples from two normal distributions, one with mean 5 and stdev 3, and the other with mean 6 and stdev 4. Use the functions above to create a histogram of their sum.\n",
    "\n",
    "Compare this to a normal distrubution with mean 11 and stdev 5.\n",
    "\n",
    "<!--\n",
    "#solution\n",
    "np.random.seed(2)\n",
    "num_samples = 100000\n",
    "bins = bins = 100\n",
    "a1_samp = np.random.normal(loc = 5, scale = 3, size = num_samples)\n",
    "a2_samp = np.random.normal(loc = 6, scale = 4, size = num_samples)\n",
    "\n",
    "out_samp = f(a1_samp, a2_samp)\n",
    "\n",
    "p, x = p_histogram(out_samp, bins = bins)\n",
    "\n",
    "plt.plot(x,p)\n",
    "plt.plot(x, scipy.stats.norm.pdf(x, loc =11, scale = 5))\n",
    "\n",
    "print(\"mean\", np.mean(out_samp))\n",
    "print(\"std\", np.std(out_samp))\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## 5.2 Fitting Exercise 2\n",
    "\n",
    "What about something even more complicated, like\n",
    "$$g(a_1, a_2) =(\\sqrt{|a_1|} + \\sqrt{|a_2|})*(a_1-a_2)$$\n",
    "\n",
    "You can do the error propogation by yourself, but it is going to be really complicated and a lot of algebra! But, with numpy, this is the exact same amount of work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:#BA2220\">>>>EXERCISE</span>\n",
    "\n",
    "Define the function <code>g()</code>, as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(a_1, a_2):\n",
    "    term_1 = np.sqrt(np.abs(a_1))+ np.sqrt(np.abs(a_2))\n",
    "    term_2 =  np.power(a_1-a_2, 1.0)\n",
    "    return term_1*term_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:#BA2220\">>>>EXERCISE</span>\n",
    "\n",
    "Again, get two sets of random samples from two normal distributions, one with mean 5 and stdev 3, and the other with mean 6 and stdev 4. Use the functions above to create a histogram of $g(a_1,a_2)$. Find the mean and stdev of this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "num_samples = 1000000\n",
    "bins = bins = 100\n",
    "a1_samp = np.random.normal(loc = 5, scale = 3, size = num_samples)\n",
    "a2_samp = np.random.normal(loc = 6, scale = 4, size = num_samples)\n",
    "\n",
    "out_samp = g(a1_samp, a2_samp)\n",
    "print(out_samp)\n",
    "p, x = p_histogram(out_samp, bins = bins)\n",
    "\n",
    "plt.plot(x,p)\n",
    "\n",
    "print(\"mean\", np.mean(out_samp))\n",
    "print(\"std\", np.std(out_samp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## 5.3 Measuring the Boltzmann Constant from Johnson Noise\n",
    "\n",
    "Now let us use this example to do a little bit of analysis from Junior Lab to measure the Boltzmann constant. This comes from an experiment called Johnson noise, which is thermal noise across a resistor.\n",
    "\n",
    "$$V^2 = 4 R k_B T \\int_{0}^{\\infty} \\frac{g(f)^2}{1+ (2\\pi R C f)^2}$$\n",
    "\n",
    "We measured $g$ as a function of $f$, and we have some uncertainty on $R$, and we also have some uncertainty on $C$. How do we compute the uncertainty on this complicated quantity?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "Run the cells below to define the arrays of experimental data (this is real data from Junior Lab)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.array([   200.,    300.,    400.,    500.,    600.,    700.,    800.,\n",
    "          900.,   1000.,   1100.,   1200.,   1300.,   1400.,   1500.,\n",
    "         1700.,   2000.,   3000.,   4000.,   5000.,   7000.,  10000.,\n",
    "        13000.,  15000.,  17000.,  20000.,  25000.,  30000.,  35000.,\n",
    "        40000.,  45000.,  50000.,  55000.,  60000.,  65000.,  70000.,\n",
    "        75000.,  80000.,  85000.,  90000.,  95000., 100000.])\n",
    "\n",
    "gain = np.array([  1.56572199,   7.56008454,  24.23507344,  58.36646477,\n",
    "       119.11924863, 215.75587662, 354.79343025, 517.34083494,\n",
    "       679.81395988, 805.18954729, 877.53623188, 944.14612835,\n",
    "       951.12203586, 981.66551215, 976.08071562, 971.57565072,\n",
    "       991.33195051, 974.54482165, 968.02100388, 970.96127868,\n",
    "       972.70192708, 980.9122768 , 983.62597547, 981.85446382,\n",
    "       964.75994752, 984.27991886, 959.44478862, 975.87335094,\n",
    "       906.24841379, 831.8699187 , 695.5940221 , 562.69096627,\n",
    "       426.50959034, 328.93671408, 248.14630158, 198.16023325,\n",
    "       150.59357167, 121.00349255, 100.86777721,  79.42663031,\n",
    "        63.20952534])\n",
    "\n",
    "gain_error = np.array([5.21317443e-03, 3.11522352e-02, 1.17453781e-01, 1.54063502e-01,\n",
    "       1.27335068e+00, 1.27124575e+00, 1.62862522e+00, 8.07632112e-01,\n",
    "       1.39800408e+00, 1.52872753e+00, 9.26100943e-01, 2.07700290e+00,\n",
    "       2.41624111e+00, 2.48737608e+00, 2.66446131e+00, 6.30956544e+00,\n",
    "       2.48543922e+00, 5.85031911e+00, 5.36245736e+00, 5.03316166e+00,\n",
    "       5.96042863e+00, 1.80119083e+00, 2.19189309e+00, 4.76416499e+00,\n",
    "       2.60518705e+00, 8.91016625e-01, 8.68517783e-01, 7.60893395e-02,\n",
    "       1.12595429e+00, 9.59211786e-01, 2.11207039e+00, 1.54206027e+00,\n",
    "       6.15658573e-01, 2.21068956e+00, 1.93131996e+00, 1.17159272e+00,\n",
    "       1.02084395e+00, 6.45939329e-01, 1.15822783e+00, 1.50426555e-01,\n",
    "       2.64213908e-01])\n",
    "\n",
    "resistances = np.array([477.1e3, 810e3, 99.7e3, 502.3e3, 10.03e3]) \n",
    "\n",
    "resistance_uncertainty = np.array([0.2e3, 2e3, 0.2e3, 0.3e3, 0.3e3])\n",
    "\n",
    "cap = 125e-12\n",
    "dcap = 14e-12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "Plot the gain as a function of f, with error bars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(f, gain, yerr= gain_error, fmt = '-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "[WHAT ARE WE DOING HERE?]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import trapz\n",
    "\n",
    "def mc_compute(freq, gain, gain_error, r, rerr, cap, cap_err, n_samp):\n",
    "    samples = []\n",
    "    for k in range(n_samp):\n",
    "        mc_gain = gain + np.random.normal(len(gain))*gain_error\n",
    "        mc_r = r + rerr*np.random.normal(1)\n",
    "        mc_cap = cap + cap_err*np.random.normal(1)\n",
    "        mc_integrand = mc_gain**2.0/(1+ (2*np.pi*mc_r*mc_cap*freq)**2.0)\n",
    "        mc_int = scipy.integrate.trapz(mc_integrand, freq)\n",
    "        samples.append(mc_r*mc_int)\n",
    "    return np.array(samples)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "[WHAT ARE WE DOING HERE?]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = mc_compute(f, gain, gain_error, resistances[0], resistance_uncertainty[0], cap, dcap,100000)\n",
    "p, x = p_histogram(samples, bins = 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "[WHAT ARE WE DOING HERE?]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2rmsd4t = np.array([2.57337556e-08, 1.96214066e-08, 2.21758082e-08, 2.38320749e-08,\n",
    "       7.31633110e-09])\n",
    "v2rmsd4t_unc = np.array([1.25267830e-09, 1.46644504e-09, 1.08426579e-09, 1.77538860e-09,\n",
    "       2.07583938e-10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "[WHAT ARE WE DOING HERE?]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgr = []\n",
    "rgr_unc = []\n",
    "for k in range(5):\n",
    "    samples = mc_compute(f, gain, gain_error, resistances[k], resistance_uncertainty[k], cap, dcap,10000)\n",
    "    rgr.append(np.mean(samples))\n",
    "    rgr_unc.append(np.std(samples))\n",
    "rgr = np.array(rgr)  \n",
    "rgr_unc = np.array(rgr_unc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(rgr, v2rmsd4t, yerr = v2rmsd4t_unc, xerr= rgr_unc, fmt = 'o' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "[WHAT ARE WE DOING HERE?]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_model(x, k, b):\n",
    "    return x/k+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lmfit.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmod = Model(linear_model)\n",
    "lmod.set_param_hint(name = 'k', value = 1)\n",
    "lmod.set_param_hint(name = 'b', value = 1)\n",
    "result = lmod.fit(1e-15*rgr, x = v2rmsd4t*1e8, weights = 1/(rgr_unc*1e-15))\n",
    "print(result.fit_report())\n",
    "result.plot_fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:purple\">>>>QUESTION</span>\n",
    "\n",
    "\n",
    "Question text needed...\n",
    "\n",
    "\n",
    "<br>\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
