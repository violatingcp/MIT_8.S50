{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "<hr style=\"height: 1px;\">\n",
    "<i>This code was authored by the 8.S50x Course Team, Copyright 2021 MIT All Rights Reserved.</i>\n",
    "<hr style=\"height: 1px;\">\n",
    "<br>\n",
    "\n",
    "# RECITATION 4: Multivariate continuous distributions\n",
    "\n",
    "<br>\n",
    "<!--end-block--> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## 4.0 Overview of Learning Objectives\n",
    "\n",
    "In this recitation we will explore the following objectives:\n",
    "\n",
    "- fill in information\n",
    "\n",
    "<br>\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## 4.1 Definitions\n",
    "\n",
    "### Multivariate Continuous Distributions and Covariance\n",
    "\n",
    "We can define a joint distribution function for two variables as $F(x,y)=P\\{(x'<x)\\cap(y'<y)\\}$.\n",
    "\n",
    "Some properties:\n",
    "\n",
    "- $F(\\infty,\\infty)=1$\n",
    "- $F(-\\infty,y)=F(x,-\\infty)=0$\n",
    "\n",
    "$F$ also has to be monotone increasing. \n",
    "\n",
    "We can define the probability density (which is vastly more useful) based on this: $f(x,y)=\\frac{\\partial^2F}{\\partial x\\partial y}$\n",
    "\n",
    "In the discrete case, the density is $p(x,y)=P(x'=x,y'=y)$. This mixed partial is sort of the infinitesimal limit for this in a continuous case.\n",
    "\n",
    "All this gives us our normalization: $\\int_x\\int_yf(x,y)\\,\\mathrm{d}x\\mathrm{d}y=1$\n",
    "\n",
    "Given a joint distribution, can we extract the marginal distributions by projecting out one of the variables:\n",
    "$f_x(x)=\\int f(x,y)\\,\\mathrm{d}y$    and    $f_y(y)=\\int f(x,y)\\,\\mathrm{d}x$\n",
    "\n",
    "And Bayes’ Theorem will give us conditional probabilities if we want them: $f_x(x\\mid y)=\\frac{f(x,y)}{f_y(y)}$\n",
    "\n",
    "Moments of multivariate distributions\n",
    "Given a joint distribution, we can calculate its moments.\n",
    "\n",
    "Means: $\\mu_x=E(x)$ and $\\mu_y=E(y)$\n",
    "Variances: $\\sigma_x^2=E((x-\\mu_x)^2)$ and $\\sigma_y^2=E((y-\\mu_y)^2)$ also $\\sigma_{xy}=E((x-\\mu_x)(y-\\mu_y))$\n",
    "\n",
    "In general, $\\mu_{\\ell m}=E(x^\\ell y^m)$ and $\\mu_{\\ell m}'=E[(x-\\mu_x)^\\ell(y-\\mu_y)^m]$\n",
    "\n",
    "How do you calculate these expectation values? $E(g(x,y))=\\int_x\\int_y g(x,y)\\cdot f(x,y)\\,\\mathrm{d}x\\,\\mathrm{d}y$\n",
    "\n",
    "The interesting moment here is the mixed moment: $\\sigma_{xy}=E((x-\\mu_x)(y-\\mu_y))$\n",
    "\n",
    "This is called the covariance. Sometime we write it as $\\text{cov}(x,y)$. It can also be calculated as $E(xy)-E(x)E(y)$.\n",
    "\n",
    "### Correlation\n",
    "\n",
    "If the covariance is nonzero, we say that $x$ and $y$ are correlated. \n",
    "This means that the mean value of $y$ depends on the chosen value for $x$, and vice versa.\n",
    "For example a person’s height is correlated with their weight.\n",
    "\n",
    "One issue here is that $\\text{cov}(x,y)$ is not bounded. So it’s hard to look at this value and gauge the degree of correlation. To solve this we use a dimensionless correlation coefficient,\n",
    "$\\rho_{xy}=\\frac{\\sigma_{xy}}{\\sigma_x\\sigma_y}$\n",
    "\n",
    "Because of Cauchy-Schwarz, $\\lvert\\rho_{xy}\\rvert\\leq 1$.\n",
    "This $\\rho$ is called Pearson’s correlation coefficient and is sometimes called $r$. It measures the linear relationship between two variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## 4.2 Covariance and correlation\n",
    "\n",
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "Let's build some intuition with covariance. Run the cells below to get data from the .txt files in this directory. The data are from three groups: noise, slope, and nonlinear. There are 7 different data sets for each group. \n",
    "\n",
    "The \"noise\" group comprises data sets with different slopes and noise levels.\n",
    "\n",
    "The \"slope\" group comprises data sets with different slopes and fixed noise levels.\n",
    "\n",
    "The \"nonlinear\" group has various nonlinear data sets.\n",
    "\n",
    "Below, the function \"get_data\" will get the data from the kth data set in the group that is indicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "def get_data(k,group):\n",
    "    pts = np.genfromtxt('%s_%d.txt' % (group,k), delimiter=',')    # read in file\n",
    "    x = [n[0] for n in pts]    # get x values\n",
    "    y = [n[1] for n in pts]    # get y values\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "Plot the data from all data sets for the group \"noise.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see what the data look like\n",
    "fig, ax = plt.subplots(nrows=1, ncols=7, figsize=(21,3))\n",
    "for k in range(len(ax)):\n",
    "    x,y = get_data(k,'noise')\n",
    "    ax[k].scatter(x,y, s=1)\n",
    "    ax[k].title.set_text('Plot %d'%(k+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "Define a function that computes the correlation coefficient for a given data set. Print the covariance matrix and correlation coefficient for one of the plots above, defined by the variable \"plotnum.\" Change \"plotnum\" to see how these values change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_coefficient(cov_matrix):\n",
    "    return cov_matrix[0][1]/(np.sqrt(cov_matrix[0][0]*cov_matrix[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotnum = 2\n",
    "x,y = get_data(plotnum-1,'noise')\n",
    "M = np.cov(x,y)\n",
    "print(M)\n",
    "print(correlation_coefficient(M))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "Plot the data from all data sets for the group \"slope.\" Similarly, pint the covariance matrix and correlation coefficient for one of the plots, defined by the variable \"plotnum.\" Change \"plotnum\" to see how these values change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependence on slope\n",
    "fig, ax = plt.subplots(nrows=1, ncols=7, figsize=(21,3))\n",
    "for k in range(len(ax)):\n",
    "    x,y = get_data(k,'slope')\n",
    "    ax[k].scatter(x,y, s=1)\n",
    "    ax[k].title.set_text('Plot %d'%(k+1))\n",
    "    ax[k].set_ylim(-1.1,1.1)\n",
    "    ax[k].set_xlim(-1.1,1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotnum = 1\n",
    "x,y = get_data(plotnum-1,'slope')\n",
    "M = np.cov(x,y)\n",
    "print(M)\n",
    "print(correlation_coefficient(M))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "Finally, plot the data from all data sets for the group \"nonlinear.\" Again, pint the covariance matrix and correlation coefficient for one of the plots, defined by the variable \"plotnum.\" Change \"plotnum\" to see how these values change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nonlinearities\n",
    "fig, ax = plt.subplots(nrows=1, ncols=7, figsize=(21,3))\n",
    "for k in range(len(ax)):\n",
    "    x,y = get_data(k,'nonlinear')\n",
    "    ax[k].scatter(x,y, s=1)\n",
    "    ax[k].title.set_text('Plot %d'%(k+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotnum = 6\n",
    "x,y = get_data(plotnum-1,'nonlinear')\n",
    "M = np.cov(x,y)\n",
    "print(M)\n",
    "print(correlation_coefficient(M))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:purple\">>>>QUESTION</span>\n",
    "\n",
    "\n",
    "[WHAT WERE THEY TRYING TO LEARN?]\n",
    "\n",
    "<br>\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
