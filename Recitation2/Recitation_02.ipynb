{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "<hr style=\"height: 1px;\">\n",
    "<i>This code was authored by the 8.S50x Course Team, Copyright 2021 MIT All Rights Reserved.</i>\n",
    "<hr style=\"height: 1px;\">\n",
    "<br>\n",
    "\n",
    "# RECITATION 2: Error Propagation & Fourier Analysis\n",
    "---\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "\n",
    "## 2.0 Overview of Learning Objectives\n",
    "\n",
    "In this recitation we will explore the following objectives:\n",
    "\n",
    "- Understand error propagation\n",
    "- Propagate Gaussian errors through arbitrary functions using Numpy\n",
    "- Understand the frequency analysis of continuous and discrete time signals\n",
    "- Visualize the connection between time and frequency space\n",
    "- Characterize the energy/power carried by different frequencies\n",
    "- Filter and denoise a signal by visualizing its spectral content\n",
    "\n",
    "<br>\n",
    "The following installation commands may come in handy:\n",
    "\n",
    "conda install numpy scipy matplotlib lmfit pyaudio\n",
    "\n",
    "pip3 install https://sigproc.mit.edu/_static/fall21/software/lib6003-0.0.4.tar.gz\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## 2.1 Error Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.0 Motivation: Lab Reports and Beyond\n",
    "- We often encounter functions of measured quantities with associated independent Gaussian errors\n",
    "- Often these functions can be treated with standard error propagration: $ \\Delta f(\\{x_i\\}) = \\sqrt{\\sum_i (\\partial f / \\partial x_i)^2 (\\Delta x_i)^2} $\n",
    "- Sometimes things get complicated\n",
    "    - A good physicist is (somewhat) lazy\n",
    "- We can use NumPy to help us propagate errors through more complex functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.1 A (Very) Simple Example\n",
    "\n",
    "Suppose we have data points ($x,y$) with independent gaussian errors $\\Delta x$ and $\\Delta y$. We want to compute $f(x,y) = x + y$ and its error.\n",
    "\n",
    "Using our error propagation formula above we obtain: $\\Delta f = \\sqrt{(\\Delta x)^2 + (\\Delta y)^2} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "\n",
    "def f(x, y):\n",
    "    return x + y\n",
    "\n",
    "def delta_f(delta_x, delta_y):\n",
    "    return np.sqrt((delta_x**2.)+(delta_y**2.))\n",
    "\n",
    "x_val = 5.\n",
    "x_err = 2.\n",
    "\n",
    "y_val = 9.\n",
    "y_err = 2.\n",
    "\n",
    "print(\"f(x) = %f +/- %f\" % (f(x_val, y_val), delta_f(x_err, y_err)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try using NumPy to run actual gaussian distributions through this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "N_SAMPLES = 100000\n",
    "N_BINS = 100\n",
    "x_samples = np.random.normal(loc = x_val, scale = x_err, size = N_SAMPLES)\n",
    "y_samples = np.random.normal(loc = y_val, scale = y_err, size = N_SAMPLES)\n",
    "\n",
    "f_samples = f(x_samples, y_samples)\n",
    "\n",
    "counts, bin_edges = np.histogram(f_samples, bins = N_BINS, density = True)\n",
    "bin_centers = 0.5*(bin_edges[:-1]+bin_edges[1:])\n",
    "\n",
    "plt.plot(bin_centers,counts)\n",
    "plt.plot(bin_centers, scipy.stats.norm.pdf(bin_centers, loc = f(x_val, y_val), scale = delta_f(x_err, y_err)))\n",
    "\n",
    "print(\"f(x) = %f +/- %f\" % (np.mean(f_samples), np.std(f_samples)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.2 A More Complicated Example\n",
    "\n",
    "Now let's take $g(x,y) = (\\sqrt{|x|} + \\sqrt{|y|})\\cdot (x - y)$\n",
    "\n",
    "### <span style=\"color: red\"> >> QUESTION 2.1: </span>\n",
    "Fill in the following code cell to compute the error on g using the same values of $x$ and $y$ (and their respective errors) from before:\n",
    "\n",
    "<!--\n",
    "ANSWER:\n",
    "\n",
    "np.random.seed(2)\n",
    "N_SAMPLES = 100000\n",
    "N_BINS = 100\n",
    "\n",
    "def g(x,y):\n",
    "    return (np.sqrt(np.abs(x))+np.sqrt(np.abs(y)))*(x-y)\n",
    "\n",
    "####################\n",
    "# Insert Code Here #\n",
    "####################\n",
    "\n",
    "g_samples = g(x_samples, y_samples)\n",
    "g_val = np.mean(g_samples)\n",
    "g_err = np.std(g_samples)\n",
    "\n",
    "\n",
    "counts, bin_edges = np.histogram(g_samples, bins = N_BINS, density = True)\n",
    "bin_centers = 0.5*(bin_edges[:-1]+bin_edges[1:])\n",
    "\n",
    "plt.plot(bin_centers,counts)\n",
    "\n",
    "print(\"g(x) = %f +/- %f\" % (g_val, g_err))\n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "N_SAMPLES = 100000\n",
    "N_BINS = 100\n",
    "\n",
    "def g(x,y):\n",
    "    return (np.sqrt(np.abs(x))+np.sqrt(np.abs(y)))*(x-y)\n",
    "\n",
    "####################\n",
    "# Insert Code Here #\n",
    "####################\n",
    "\n",
    "g_samples = None # Placeholder Value - Fill in the correct line\n",
    "g_val = None # Placeholder Value - Fill in the correct line\n",
    "g_err = None # Placeholder Value - Fill in the correct line\n",
    "\n",
    "####################\n",
    "\n",
    "counts, bin_edges = np.histogram(g_samples, bins = N_BINS, density = True)\n",
    "bin_centers = 0.5*(bin_edges[:-1]+bin_edges[1:])\n",
    "\n",
    "plt.plot(bin_centers,counts)\n",
    "\n",
    "print(\"g(x) = %f +/- %f\" % (g_val, g_err))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.3 Johnson Noise\n",
    "Let's apply this to something slightly more useful, such as measuring the Boltzmann constant. We can use Johnson Noise (the thermal noise across a resistor), which is defined by:\n",
    "\n",
    "$$\\frac{V^2}{4 T} = k_B R\\int_{0}^{\\infty} \\frac{g(f)^2}{1+ (2\\pi R C f)^2}$$\n",
    "\n",
    "Suppose we measured $g$ as a function of $f$, and we have some uncertainties on $R$ and $C$. Let's compute the total uncertainty on this complicated quantity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = np.array([   200.,    300.,    400.,    500.,    600.,    700.,    800.,\n",
    "          900.,   1000.,   1100.,   1200.,   1300.,   1400.,   1500.,\n",
    "         1700.,   2000.,   3000.,   4000.,   5000.,   7000.,  10000.,\n",
    "        13000.,  15000.,  17000.,  20000.,  25000.,  30000.,  35000.,\n",
    "        40000.,  45000.,  50000.,  55000.,  60000.,  65000.,  70000.,\n",
    "        75000.,  80000.,  85000.,  90000.,  95000., 100000.])\n",
    "\n",
    "gain = np.array([  1.56572199,   7.56008454,  24.23507344,  58.36646477,\n",
    "       119.11924863, 215.75587662, 354.79343025, 517.34083494,\n",
    "       679.81395988, 805.18954729, 877.53623188, 944.14612835,\n",
    "       951.12203586, 981.66551215, 976.08071562, 971.57565072,\n",
    "       991.33195051, 974.54482165, 968.02100388, 970.96127868,\n",
    "       972.70192708, 980.9122768 , 983.62597547, 981.85446382,\n",
    "       964.75994752, 984.27991886, 959.44478862, 975.87335094,\n",
    "       906.24841379, 831.8699187 , 695.5940221 , 562.69096627,\n",
    "       426.50959034, 328.93671408, 248.14630158, 198.16023325,\n",
    "       150.59357167, 121.00349255, 100.86777721,  79.42663031,\n",
    "        63.20952534])\n",
    "\n",
    "gain_uncertainty = np.array([5.21317443e-03, 3.11522352e-02, 1.17453781e-01, 1.54063502e-01,\n",
    "       1.27335068e+00, 1.27124575e+00, 1.62862522e+00, 8.07632112e-01,\n",
    "       1.39800408e+00, 1.52872753e+00, 9.26100943e-01, 2.07700290e+00,\n",
    "       2.41624111e+00, 2.48737608e+00, 2.66446131e+00, 6.30956544e+00,\n",
    "       2.48543922e+00, 5.85031911e+00, 5.36245736e+00, 5.03316166e+00,\n",
    "       5.96042863e+00, 1.80119083e+00, 2.19189309e+00, 4.76416499e+00,\n",
    "       2.60518705e+00, 8.91016625e-01, 8.68517783e-01, 7.60893395e-02,\n",
    "       1.12595429e+00, 9.59211786e-01, 2.11207039e+00, 1.54206027e+00,\n",
    "       6.15658573e-01, 2.21068956e+00, 1.93131996e+00, 1.17159272e+00,\n",
    "       1.02084395e+00, 6.45939329e-01, 1.15822783e+00, 1.50426555e-01,\n",
    "       2.64213908e-01])\n",
    "\n",
    "resistance = np.array([477.1e3, 810e3, 99.7e3, 502.3e3, 10.03e3]) \n",
    "resistance_uncertainty = np.array([0.2e3, 2e3, 0.2e3, 0.3e3, 0.3e3])\n",
    "\n",
    "capacitance = 125e-12\n",
    "capacitance_uncertainty = 14e-12\n",
    "\n",
    "v2rmsd4t = np.array([2.57337556e-08, 1.96214066e-08, 2.21758082e-08, 2.38320749e-08,\n",
    "       7.31633110e-09])\n",
    "v2rmsd4t_uncertainty = np.array([1.25267830e-09, 1.46644504e-09, 1.08426579e-09, 1.77538860e-09,\n",
    "       2.07583938e-10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import trapz\n",
    "\n",
    "def mc_compute(freq, gain, gain_error, r, rerr, cap, cap_err, n_samp):\n",
    "    samples = []\n",
    "    for k in range(n_samp):\n",
    "        mc_gain = gain + np.random.normal(len(gain))*gain_error\n",
    "        mc_r = r + rerr*np.random.normal(1)\n",
    "        mc_cap = cap + cap_err*np.random.normal(1)\n",
    "        mc_integrand = mc_gain**2.0/(1+ (2*np.pi*mc_r*mc_cap*freq)**2.0)\n",
    "        mc_int = scipy.integrate.trapz(mc_integrand, freq)\n",
    "        samples.append(mc_r*mc_int)\n",
    "    return np.array(samples)\n",
    "\n",
    "\n",
    "rgr = []\n",
    "rgr_unc = []\n",
    "for k in range(5):\n",
    "    samples = mc_compute(frequency, gain, gain_uncertainty, resistance[k], resistance_uncertainty[k], capacitance, capacitance_uncertainty,10000)\n",
    "    rgr.append(np.mean(samples))\n",
    "    rgr_unc.append(np.std(samples))\n",
    "rgr = np.array(rgr)  \n",
    "rgr_unc = np.array(rgr_unc)\n",
    "\n",
    "\n",
    "plt.errorbar(rgr, v2rmsd4t, yerr = v2rmsd4t_uncertainty, xerr= rgr_unc, fmt = 'o' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lmfit.models import Model\n",
    "\n",
    "def linear_model(x, k, b):\n",
    "    return x/k+b\n",
    "\n",
    "lmod = Model(linear_model)\n",
    "lmod.set_param_hint(name = 'k', value = 1)\n",
    "lmod.set_param_hint(name = 'b', value = 1)\n",
    "result = lmod.fit(1e-15*rgr, x = v2rmsd4t*1e8, weights = 1/(rgr_unc*1e-15))\n",
    "print(result.fit_report())\n",
    "result.plot_fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "----\n",
    "## 2.2.0 Motivation: Gravitational Waves/LIGO \n",
    "\n",
    "- Every massive object that accelerates produces gravitational waves. \n",
    "- These can be intuitively understood as \"ripples\" in space-time that travel at the speed of light. \n",
    "- Continuous gravitational waves are thought to be produced by spinning massive objects like a neutron star. \n",
    "- Compact Binary Inspiral Gravitational Waves are of particular interest and show up as significant detections in LIGO \n",
    "    - Binary Neutron Stars (BNS)\n",
    "    - Binary Black Hole (BBH)\n",
    "    - Neutron Star-Black Hole Binary (NSBH)\n",
    "\n",
    "\n",
    "<br>\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='assets/images/ligo.jpg' alt=\"drawing\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Measured on Earth, cataclysmic mergers change the length of a 4km LIGO arm by a thousandth of the width of a proton. \n",
    "- Strain is the instrument's detected space change within an arm in comparison to the total space (length) of the arm. \n",
    "- In the event of a detectable merger this strain data will form a \"gravitational wave signal\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## 2.2 Frequency Analysis\n",
    "\n",
    "<img src='assets/images/strain.png' />\n",
    "\n",
    "- Is there another way of thinking about our data, in a way that may be more useful for our particular application? \n",
    "- If time-series data is too noisy/messy for easy analysis, we can consider the underlying frequency representation of the same information.\n",
    "\n",
    "**Fourier Transform**<br />\n",
    "*Space or Time Functions* &rarr; *Spatial or Temporal Frequencies* <br />\n",
    "**Inverse Fourier Transform**<br />\n",
    "*Spatial or Temporal Frequencies* &rarr; *Space or Time Functions*\n",
    "\n",
    "### What do I mean by \"Frequency Space\", \n",
    "\n",
    "- In 1807 Joseph Fourier posited that any periodic signal could be represented by a sum of a particular set of harmonic sinusoids. \n",
    "- i.e. all signals can be decomposed into elemental sine and cosine components\n",
    "$$f(t) = c_0 + \\sum\\limits_{k=1}^\\infty (c_k\\cos(k\\omega_o t) + d_k\\sin(k\\omega_o t))$$\n",
    "\n",
    "<br>\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='assets/images/decompose.gif'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='assets/images/recompose.gif'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:red\">>>QUESTION 2.2</span>\n",
    "\n",
    "\n",
    "Convince yourself that the follwing sinusoidal decomposition is indeed the case.\n",
    "$$e^{ix} = \\cos(x) + i\\sin(x)$$\n",
    "<img src='assets/images/plane.png'>\n",
    "\n",
    "<br>\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='assets/images/sawtooth.gif'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## 2.3 The Discrete Fourier Transform\n",
    "\n",
    "***Overview***\n",
    "- These decomposed sinusoids are characterized by their frequencies.\n",
    "- Want a mathematical machine that treats signals with a given frequency different than other frequencies. \n",
    "\n",
    "***Analysis (Discrete Fourier Transform)***\n",
    "- We can inspect a signal and ask how much of one frequency is present.\n",
    "- Multiply our signal by a sinusoid of a particular frequency to ask how \"similar\" the two are. \n",
    "- Call these the *Fourier frequency coefficients.*\n",
    "$$ X[k] = \\frac{1}{N}\\sum\\limits_{n=1}^{N-1} x[n]e^{-i\\frac{2\\pi k}{N} n} $$ \n",
    "<br>\n",
    "\n",
    "| Syntax      | Description |\n",
    "| ----------- | ----------- |\n",
    "| $ x[n]$ | Signal for analysis |\n",
    "| $ e^{-i\\frac{2\\pi k}{N} n}$ | Frequency component k we compare to |\n",
    "| $ X[k] $ | How similar to the sinusoid of component k |\n",
    "\n",
    "$$X[k] = \\frac{1}{N}\\sum\\limits_{n=1}^{N-1} (e^{-i\\frac{2\\pi j}{N} n})(e^{i\\frac{2\\pi k}{N} n}) = \\frac{N}{N}\\delta_{jk} $$ \n",
    "<br>\n",
    "\n",
    "***The \"DC\" ($X[0]$) Term***\n",
    "- Is the 0 frequency component of a signal.\n",
    "- Represents the constant offset of a signal (if any). \n",
    "- Represents the *average value* of a signal over one period. \n",
    "\n",
    "\n",
    "***Synthesis (Inverse Discrete Fourier Transform)***\n",
    "- Can recompose signal with these coefficients.\n",
    "$$x[n] = \\sum\\limits_{k=0}^{N-1}X[k]e^{i\\frac{2\\pi k}{N} n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'assets/images/box_transform.PNG'>\n",
    "<img src = 'assets/images/box_transform_2.PNG'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Notice that when we tightened our signal in time, we made it wider in frequency. This is a visual representation of the famous _uncertainity principle_! It arises in quantum mechanics because position and momentum obey the same Fourier relationship that time and frequency do above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## 2.4 Spectral Density/Power Spectrums\n",
    "\n",
    "\n",
    "##### First the Energy Spectral Density (ESD)\n",
    "- Describes how the energy of a signal is distributed with frequency. \n",
    "- The squared magnitude of each frequency \n",
    "- Good for localised transients (pulse-like signals) whose energy is concentrated around one time window. \n",
    "$$\\overline{S}_{xx}(f) = |{\\hat{x}(f)}|^2$$\n",
    "\n",
    "#####  Power Spectral Density (PSD)\n",
    "- For continuous signals over all time, the power spectal density is more apt. \n",
    "- The power spectral density of a time series is the measure of the signal's power content in the frequency components that compose that signal.\n",
    "$$S_{xx}(f) = \\lim_{T \\to \\infty} \\frac{1}{T}|\\hat{x}_T(f)|^2 \\ \\textrm{where} \\ x_T \\ \\textrm{is the signal, windowed}$$\n",
    "$$S_{xx}(f) = \\int_{-\\infty}^{\\infty} R_{xx}(\\tau)e^{-i2\\pi f\\tau}d\\tau = \\hat{R}_{xx}(f) $$\n",
    "- Defined as the normalized limit of the ESD for the windowed signal.\n",
    "- Also represented as the Fourier transform of the autocorrelation function $R_{xx}(\\tau)$ (informally, the Fourier transform of how similar the signal is to itself). \n",
    "\n",
    "#####  Amplitude Spectral Density (PSD)\n",
    "- Amplitude Spectral Density (ASD) is just the square-root of the PSD and is useful when the shape of the spectrum is rather constant, since variations in the ASD will then be proportional to variations in the signal's voltage itself.\n",
    "\n",
    "<img src = 'assets/images/spectrum.png'>\n",
    "\n",
    "- Dominated by low frequencies and sharp spectral lines throughout. \n",
    "- From instrumental artifacts\n",
    "    - Seismic noise\n",
    "    - \"Violin Modes\" from the suspension fibers of the LIGO mirrors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## 2.5 Spectrograms Q-Transform\n",
    "- To better understand a system, we can bridge the gap between the frequency and time domains with another transform.\n",
    "- The Short-Time Fourier Transform takes the Fourier transform within shorter time segments. \n",
    "- The resulting visual representation is called a \"spectrogram\" which can be thought of as a series of Fourier transforms stacked on their side. \n",
    "\n",
    "<img src = 'assets/images/motif_sgram.png'>\n",
    "\n",
    "- The Q-Transform breaks these intervals up with logarithmic spacing for when the data are better represented as such (often times in audio.)\n",
    "\n",
    "<img src = 'assets/images/stft_vs_q_gautham.png'>\n",
    "<!-- https://ccrma.stanford.edu/~gautham/Site/Multipitch.html -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Whitening data\n",
    "- From the ASD above, we can see that noise fluctuations are much larger at low and high frequencies and near spectral lines. \n",
    "- To better visualize deviations from the noise, it is useful to employ a technique called \"whitening\".\n",
    "- Whitening takes the data and attempts to make the power spectral density flat (i.e. normalize the power at all frequencies) so that excess power at any frequency is more obvious. \n",
    "\n",
    "- Persisent signals like noise will have their power spread about the entire time window. \n",
    "- Localized signals will have all of their power in one region region (evident spikes)\n",
    "\n",
    "- Achieved very informally by applying the inverse frequency response of the raw signal. \n",
    "\n",
    "Example: Trasmitted power in one of the interferoeter arms with two large glitches with a frequency around 5-50Hz\n",
    "\n",
    "<img src = 'assets/images/whiteningexample_gwpy.png'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering\n",
    "- The amplification/attenuation of frequency components.\n",
    "- Can be done in the time domian but best viewed from the frequency domain. \n",
    "    - **Multiplication in the frequency domain**\n",
    "    - A set of scale factors H() which is refered to as the frequency response of the system.\n",
    "<img src ='assets/images/filters.png'>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Packages\n",
    "import math\n",
    "import numpy as np\n",
    "import lib6003\n",
    "import matplotlib.pyplot as plt\n",
    "from lib6003.audio import wav_write\n",
    "from lib6003.audio import wav_file_play\n",
    "from lib6003.audio import wav_read\n",
    "from lib6003.audio import wav_play\n",
    "from lib6003.fft import fft\n",
    "from lib6003.fft import ifft\n",
    "from scipy.io.wavfile import write"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DFT Filtering\n",
    "- We can filter using DFT coefficients by scaling them appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Noise-Free #3 \n",
    "wav_file_play('assets/audio/ocean_man_raw.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Bass Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,fs =wav_read('assets/audio/ocean_man_raw.wav')\n",
    "## x is the data, fs is the sampling frequency\n",
    "N = len(x)\n",
    "## f = k*fs/N\n",
    "## k = f*N/fs\n",
    "fc = 400 #cutoff frequency in Hz; boost all frequency content below fc\n",
    "kc = int(fc*N/fs)\n",
    "\n",
    "X = fft(x)\n",
    "Y = X[:] #copy values from X\n",
    "Y[:kc] = [i*5 for i in X[:kc]]\n",
    "Y[-kc:] = [i*5 for i in X[-kc:]]\n",
    "## Amplify all the coefficients in the bass-boosted region by 5\n",
    "\n",
    "## Inverse fourier transform and recombine into a .wav file \n",
    "y = ifft(Y)\n",
    "# assert all(abs(i.imag) < 1e-12 for i in y)\n",
    "wav_play([i.real for i in y],fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Bass Isolation (Low Pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,fs = wav_read('assets/audio/ocean_man_raw.wav')\n",
    "N = len(x)\n",
    "## f = k*fs/N\n",
    "## k =f*N/fs\n",
    "fc = 400  # cutoff frequency in Hz; boost all frequency content below fc\n",
    "kc = int(fc*N/fs)\n",
    "\n",
    "X = fft(x)\n",
    "Y = X[:] # copy values from X\n",
    "Y[kc:-kc] = [i*0 for i in X[kc:-kc]]\n",
    "\n",
    "y = ifft(Y)\n",
    "# assert all(abs(i.imag) < 1e-12 for i in y)\n",
    "wav_play([i.real for i in y],fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Signal Detection and Matched Filtering\n",
    "- If we have an unknown, noisy signal we can try to detect the presence of a known signal with matched filtering. \n",
    "- If we *know* or *guess* the signal we're looking for (called the *template*), we can use it as a filter for combing the data for the presence of that template.\n",
    "- Matched filters work by maximizing the signal to noise ratio (SNR) when the matched filter detects the presence of the template signal in a noisy signal. \n",
    "- Phil will talk more about convolutions next week but we can informally think of a matched filter as:\n",
    "- \"Drag\" or sweep your template across the signal and calculate some statistic.\n",
    "- The optimal statistic suggests the presence of a signal. \n",
    "\n",
    "<img src ='template.png'>\n",
    "<img src ='SNR.png'>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Noise-Free \n",
    "wav_file_play('assets/audio/ocean_man_raw.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Noise\n",
    "wav_file_play('assets/audio/ocean_man.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Read in Data\n",
    "data, samp_rate = wav_read('assets/audio/ocean_man.wav')\n",
    "#Check length of Data\n",
    "N = len(data)\n",
    "#Take the Fourier Transform\n",
    "dft_cof = fft(data)\n",
    "k = np.linspace(0,N-1,N)\n",
    "f=k*samp_rate/N\n",
    "\n",
    "plt.plot(f,np.absolute(dft_cof))\n",
    "plt.title(\"Noisty Ocean Man Spectrum\", fontsize=18)\n",
    "plt.xlabel('Frequency $\\\\nu $', fontsize=14)\n",
    "plt.ylabel('Magnitude $|X(\\\\nu)|$', fontsize=14)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Focus in on one set of conjuagte frequencies\n",
    "plt.plot(f,np.absolute(dft_cof))\n",
    "plt.xlim(-100,5000)\n",
    "plt.ylim(0,0.01)\n",
    "plt.title(\"Noisy Ocean Man Spectrum\", fontsize=18)\n",
    "plt.xlabel('Frequency $\\\\nu $', fontsize=14)\n",
    "plt.ylabel('Magnitude $|X(\\\\nu)|$', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zoom in on artifact\n",
    "plt.plot(f,np.absolute(dft_cof))\n",
    "plt.xlim(980,1000)\n",
    "plt.ylim(0,0.008)\n",
    "plt.title(\"Noisy Ocean Man Spectrum\", fontsize=18)\n",
    "plt.xlabel('Frequency $\\\\nu $', fontsize=14)\n",
    "plt.ylabel('Magnitude $|X(\\\\nu)|$', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_cut = int((990*N/samp_rate))\n",
    "# print(k_cut)\n",
    "freqs = fft(data)\n",
    "# print(len(freqs))\n",
    "for i in range(k_cut-100,k_cut+100):\n",
    "    freqs[i]= 0\n",
    "for i in range(-k_cut-100,-k_cut+100):\n",
    "    freqs[i]= 0\n",
    "# print(len(freqs))\n",
    "f=k*samp_rate/N\n",
    "\n",
    "plt.title(\"Denoised Ocean Man Spectrum\", fontsize=18)\n",
    "plt.xlabel('Frequency $\\\\nu $', fontsize=14)\n",
    "plt.ylabel('Magnitude $|X(\\\\nu)|$', fontsize=14)\n",
    "\n",
    "plt.plot(f,np.absolute(freqs))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocean_fix = ifft(freqs)\n",
    "wav_play(ocean_fix,samp_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"xkcd.jpg\">"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cbb6e056583fd03f6322a65e9e97540b0afe957fac88728c845a07e6e1613cc6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
