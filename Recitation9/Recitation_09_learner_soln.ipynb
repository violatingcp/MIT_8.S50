{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "<hr style=\"height: 1px;\">\n",
    "<i>This code was authored by the 8.S50x Course Team, Copyright 2021 MIT All Rights Reserved.</i>\n",
    "<hr style=\"height: 1px;\">\n",
    "<br>\n",
    "\n",
    "# RECITATION 9: Deep Learning\n",
    "\n",
    "<br>\n",
    "<!--end-block--> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## 9.0 Overview of Learning Objectives\n",
    "\n",
    "In this recitation we will explore the following objectives:\n",
    "\n",
    "- fill in information\n",
    "\n",
    "<br>\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## 9.1 A Simpe Example\n",
    "\n",
    "Explanatory text needed...\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "Let's look at a simpler example. To start with, some very simple data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O3ErNwyKMeT_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "JC7q8G57E1os",
    "outputId": "cfc89f8a-4a1a-4211-f098-4091f19e58b6"
   },
   "outputs": [],
   "source": [
    "# let's make some points\n",
    "x = np.random.uniform(size=100)\n",
    "y = np.random.uniform(size=100)\n",
    "# let's label them based on whether they're above or below y=x\n",
    "# (with a little noise to make things interesting)\n",
    "Y = np.greater(x+np.random.normal(scale=0.1,size=100),y)\n",
    "X = np.array([x,y])\n",
    "#  p l o t\n",
    "plt.scatter(x,y,c=Y,cmap='winter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "squWlObaF0-A"
   },
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "Let's convert these numpy arrays to tensors using PyTorch for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xJB1whFeF4Yh"
   },
   "outputs": [],
   "source": [
    "X = torch.from_numpy(X).type(torch.FloatTensor)\n",
    "Y = torch.from_numpy(Y).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EM41Pw6nRQKb"
   },
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "Let's build our neural network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ItvtxRZOQwL4"
   },
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        # let's inherit everything from Module\n",
    "        super(Classifier,self).__init__()\n",
    "        # our network will have 3 layers: one input, one hidden, and one output\n",
    "        self.fc1 = nn.Linear(2,3)\n",
    "        self.fc2 = nn.Linear(3,2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # first layer output\n",
    "        x = self.fc1(x)\n",
    "        # using ReLU activation function\n",
    "        x = F.relu(x)\n",
    "        # getting the output\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "        \n",
    "    # predicting the class of an input\n",
    "    def predict(self,x):\n",
    "        # apply softmax to output \n",
    "        pred = F.softmax(self.forward(x))\n",
    "        ans = []\n",
    "        # pick the class with maximum weight\n",
    "        for t in pred:\n",
    "            if t[0]>t[1]:\n",
    "                ans.append(0)\n",
    "            else:\n",
    "                ans.append(1)\n",
    "        return torch.tensor(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QgR_cB9vSHiv"
   },
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "Let's get set up to train this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Puymym3kSChW"
   },
   "outputs": [],
   "source": [
    "# init the model       \n",
    "model = Classifier()\n",
    "# define the loss function \n",
    "# here we use cross-entropy loss because this is binary classification\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# define the optimizer\n",
    "# we use Adam, which adapts based on the gradient and previous SGD stpes\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wjIFyWt8SWyw"
   },
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "Now it's time to train. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jrpJWOXZSRs-"
   },
   "outputs": [],
   "source": [
    "# number of training epochs\n",
    "epochs = 100\n",
    "# let's keep track of losses\n",
    "losses = []\n",
    "for i in range(epochs):\n",
    "    # predict the model output for input\n",
    "    Y_pred = model.forward(X.T)\n",
    "    # calculate the loss\n",
    "    loss = criterion(Y_pred,Y)\n",
    "    losses.append(loss.item())\n",
    "    # clear previous gradients\n",
    "    optimizer.zero_grad()\n",
    "    # compute gradient\n",
    "    loss.backward()\n",
    "    # update weights\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Nj4Ox8eTaG3"
   },
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "How'd we do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "zRk-dZMwSp0p",
    "outputId": "2381626d-c4ba-4474-81ac-35709afceb4c"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(model.predict(X.T),Y))\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TK2NWdxST44G"
   },
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "Let's draw the decision boundary that our classifier came up with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7cNRz017TbMh"
   },
   "outputs": [],
   "source": [
    "def predict(x):\n",
    " '''returns 0 or 1 given a single input'''\n",
    " x = torch.from_numpy(x).type(torch.FloatTensor)  # numpy to tensor\n",
    " ans = model.predict(x)\n",
    " return ans.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H9t77pzKUKsv"
   },
   "outputs": [],
   "source": [
    "def plot_decision_boundary(pred,X,Y):\n",
    "    h = 0.01\n",
    "    # a grid with distance h\n",
    "    xx,yy = np.meshgrid(np.arange(0,1,h), np.arange(0,1,h))\n",
    "    # ppredict the function over the grid\n",
    "    Z = pred(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    # plot the contour and training examples\n",
    "    plt.contourf(xx, yy, Z, cmap='winter')\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=Y, cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6cSvih6dUjNy"
   },
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "Let's plot the boundary!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "id": "DuqGfjrBUiT1",
    "outputId": "f09539a0-ae66-44b1-b655-9b03b717af32"
   },
   "outputs": [],
   "source": [
    "plot_decision_boundary(lambda x : predict(x) , X.T.numpy(), Y.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:purple\">>>>QUESTION</span>\n",
    "\n",
    "\n",
    "Question text needed...\n",
    "\n",
    "\n",
    "<br>\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ihvj683xVZQ-"
   },
   "source": [
    "<!--start-block-->\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## 9.2 A More Complicated Example\n",
    "\n",
    "\n",
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "Let's try a more complicated configuration of data!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "N0ESUCF1UpP1",
    "outputId": "98387a3b-3d78-4267-d6b4-a9c43650d275"
   },
   "outputs": [],
   "source": [
    "# let's make some points\n",
    "x = np.random.uniform(size=500)\n",
    "y = np.random.uniform(size=500)\n",
    "# let's label them based on whether they're above or below y=x\n",
    "Y = np.square(x-0.5)+np.square(y-0.5)>(0.15+np.random.normal(scale=0.03,size=500))\n",
    "X = np.array([x,y])\n",
    "#  p l o t\n",
    "plt.scatter(x,y,c=Y,cmap='winter')\n",
    "\n",
    "X = torch.from_numpy(X).type(torch.FloatTensor)\n",
    "Y = torch.from_numpy(Y).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S4eHUHTgV8WN"
   },
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "Let's try our Classifier on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "Cvg4itbrVv3f",
    "outputId": "01fa6b7b-c614-4a01-90d5-0adb3bb9cda7"
   },
   "outputs": [],
   "source": [
    "# init the model       \n",
    "model = Classifier()\n",
    "# define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# number of training epochs\n",
    "epochs = 300\n",
    "# let's keep track of losses\n",
    "losses = []\n",
    "for i in range(epochs):\n",
    "    # predict the model output for input\n",
    "    Y_pred = model.forward(X.T)\n",
    "    # calculate the loss\n",
    "    loss = criterion(Y_pred,Y)\n",
    "    losses.append(loss.item())\n",
    "    # clear previous gradients\n",
    "    optimizer.zero_grad()\n",
    "    # compute gradient\n",
    "    loss.backward()\n",
    "    # update weights\n",
    "    optimizer.step()\n",
    "\n",
    "print(accuracy_score(model.predict(X.T),Y))\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "id": "coGteRetWKME",
    "outputId": "f1acbf6f-c6a5-4496-fb08-4ba93180f591"
   },
   "outputs": [],
   "source": [
    "plot_decision_boundary(lambda x : predict(x) , X.T.numpy(), Y.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:purple\">>>>QUESTION</span>\n",
    "\n",
    "\n",
    "Question text needed...\n",
    "\n",
    "\n",
    "<br>\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9rvJ5tSWSpa"
   },
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "Let's try to improve our classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xj2m2NQCWOCl"
   },
   "outputs": [],
   "source": [
    "class DenserClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        # let's inherit everything from Module\n",
    "        super(DenserClassifier,self).__init__()\n",
    "        # our network will have 4 layers: one input, two hidden, and one output\n",
    "        self.fc1 = nn.Linear(2,10)\n",
    "        self.fc2 = nn.Linear(10,10)\n",
    "        self.fc3 = nn.Linear(10,2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # first layer output\n",
    "        x = self.fc1(x)\n",
    "        # using ReLU activation function\n",
    "        x = F.relu(x)\n",
    "        # getting the output\n",
    "        x = self.fc2(x)\n",
    "         # using ReLU activation function\n",
    "        x = F.relu(x)\n",
    "        # getting the output\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "        \n",
    "    # predicting the class of an input\n",
    "    def predict(self,x):\n",
    "        # apply softmax to output \n",
    "        pred = F.softmax(self.forward(x))\n",
    "        ans = []\n",
    "        # pick the class with maximum weight\n",
    "        for t in pred:\n",
    "            if t[0]>t[1]:\n",
    "                ans.append(0)\n",
    "            else:\n",
    "                ans.append(1)\n",
    "        return torch.tensor(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EXL8yPwHW2dc"
   },
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "time 2 train 5 us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "MMhuw_GMWuSn",
    "outputId": "38b8f76b-397a-4758-a012-12e498530212"
   },
   "outputs": [],
   "source": [
    "# init the model       \n",
    "model = DenserClassifier()\n",
    "# define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# number of training epochs\n",
    "epochs = 200\n",
    "# let's keep track of losses\n",
    "losses = []\n",
    "for i in range(epochs):\n",
    "    # predict the model output for input\n",
    "    Y_pred = model.forward(X.T)\n",
    "    # calculate the loss\n",
    "    loss = criterion(Y_pred,Y)\n",
    "    losses.append(loss.item())\n",
    "    # clear previous gradients\n",
    "    optimizer.zero_grad()\n",
    "    # compute gradient\n",
    "    loss.backward()\n",
    "    # update weights\n",
    "    optimizer.step()\n",
    "\n",
    "print(accuracy_score(model.predict(X.T),Y))\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "id": "f6NpXVoyWyCl",
    "outputId": "3370920a-bcc8-4ab0-f67f-32cd8641dedb"
   },
   "outputs": [],
   "source": [
    "plot_decision_boundary(lambda x : predict(x) , X.T.numpy(), Y.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:purple\">>>>QUESTION</span>\n",
    "\n",
    "\n",
    "Question text needed...\n",
    "\n",
    "\n",
    "<br>\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DWbVVHk_XLlL"
   },
   "source": [
    "<!--start-block-->\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## 9.3 Regression Example 1\n",
    "\n",
    "\n",
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "Okay, so that's classifying things. Can we do a regression? Let's use our old supernova data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AekDPPA3W6eU",
    "outputId": "bf99aaec-1441-4cde-c9ee-46051a5d2e5b"
   },
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/violatingcp/MIT_8.S50/main/Lecture2/sn_z_mu_dmu_plow_union2.1.txt\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AwMceKY_ZGtE"
   },
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "Stealing Phil's Lecture 2 code for getting small redshift data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "HAPV-O-fYdD8",
    "outputId": "1070b4fc-d2b6-498b-f855-46765e1b93f9"
   },
   "outputs": [],
   "source": [
    "label='sn_z_mu_dmu_plow_union2.1.txt'\n",
    "\n",
    "def distanceconv(iMu):\n",
    "    power=iMu/5+1\n",
    "    return 10**power\n",
    "\n",
    "def distanceconverr(iMu,iMuErr):\n",
    "    power=iMu/5+1\n",
    "    const=np.log(10)/5.\n",
    "    return const*(10**power)*iMuErr\n",
    "\n",
    "redshift=np.array([])\n",
    "distance=np.array([])\n",
    "distance_err=np.array([])\n",
    "with open(label,'r') as csvfile:\n",
    "    plots = csv.reader(csvfile, delimiter='\\t')\n",
    "    for row in plots:\n",
    "        if float(row[1]) > 0.1:\n",
    "            continue\n",
    "        redshift = np.append(redshift,float(row[1]))\n",
    "        distance = np.append(distance,distanceconv(float(row[2])))\n",
    "        distance_err = np.append(distance_err,distanceconverr(float(row[2]),float(row[3])))\n",
    "\n",
    "plt.errorbar(redshift,distance,yerr=distance_err,marker='.',linestyle = 'None', color = 'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NhytzkBUY6O4"
   },
   "outputs": [],
   "source": [
    "X = torch.from_numpy(np.array([list(redshift*100)])).type(torch.FloatTensor).T\n",
    "Y = torch.from_numpy(np.array([list(distance/1e8)])).type(torch.FloatTensor).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4oz2FyMaX9q"
   },
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "We'll use a new model to deal with our one-dimensional input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GmygCMsubLuv"
   },
   "outputs": [],
   "source": [
    "class Regression(nn.Module):\n",
    "    def __init__(self):\n",
    "        # let's inherit everything from Module\n",
    "        super(Regression,self).__init__()\n",
    "        # our network will have 3 layers: one input, one hidden, and one output\n",
    "        self.fc1 = nn.Linear(1,5)\n",
    "        self.fc2 = nn.Linear(5,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # first layer output\n",
    "        x = self.fc1(x)\n",
    "        # using sigmoid activation function\n",
    "        x = F.sigmoid(x)\n",
    "        # getting the output\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ONT1N-Yag9W4"
   },
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "Training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "3bMJoOrMZwcW",
    "outputId": "4bcd1bc0-b531-4947-80a3-6ba52a45e2f2"
   },
   "outputs": [],
   "source": [
    "# init the model       \n",
    "model = Regression()\n",
    "# define the loss function as mean squared error this time\n",
    "criterion = nn.MSELoss()\n",
    "# define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "# number of training epochs\n",
    "epochs = 80\n",
    "# let's keep track of losses\n",
    "losses = []\n",
    "for i in range(epochs):\n",
    "    # predict the model output for input\n",
    "    Y_pred = model.forward(X)\n",
    "    # calculate the loss\n",
    "    loss = criterion(Y_pred,Y)\n",
    "    losses.append(loss.item())\n",
    "    # clear previous gradients\n",
    "    optimizer.zero_grad()\n",
    "    # compute gradient\n",
    "    loss.backward()\n",
    "    # update weights\n",
    "    optimizer.step()\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TyEytJxpg_AD"
   },
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "What do we get!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 327
    },
    "id": "jubMTChOa1Nh",
    "outputId": "06018043-47aa-407c-e7b8-da509ec1afcc"
   },
   "outputs": [],
   "source": [
    "# rescaling\n",
    "Y_pred = model.forward(X).detach().numpy() * 1e8\n",
    "# p l o t\n",
    "plt.errorbar(redshift,distance,yerr=distance_err,marker='.',linestyle = 'None', color = 'black')\n",
    "plt.plot(redshift,Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gVKgclU8hANQ",
    "outputId": "a5c6052e-db1a-46bf-89ee-3031040e56ee"
   },
   "outputs": [],
   "source": [
    "idx1 = np.random.randint(0,len(X)-1,size=30)\n",
    "idx2 = np.random.randint(0,len(X)-1,size=30)\n",
    "slope = (Y_pred[idx1]-Y_pred[idx2])/(X[idx1]-X[idx2])*100   # 100 to rescale X\n",
    "slope = slope.detach().numpy()\n",
    "H = float(1e6*3e5/np.mean(slope))\n",
    "print(H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:purple\">>>>QUESTION</span>\n",
    "\n",
    "\n",
    "Question text needed...\n",
    "\n",
    "\n",
    "<br>\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## 9.4 Regression Example 2\n",
    "\n",
    "\n",
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "One more regression for fun!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "Eg-eLyC_iSnp",
    "outputId": "8847345b-4c5b-4184-9382-2ec0655e8eb1"
   },
   "outputs": [],
   "source": [
    "# let's make some points\n",
    "x = np.random.normal(loc=5,size=50000)\n",
    "counts, bin_edges = np.histogram(x, bins=500)\n",
    "bin_centers = (bin_edges[1:]+bin_edges[:-1])/2\n",
    "\n",
    "# some testing data\n",
    "X_test = np.array([list(bin_centers)[1::10]])\n",
    "Y_test = np.array([list(counts)[1::10]])\n",
    "\n",
    "X = np.array([list(bin_centers)[::2]])\n",
    "Y = np.array([list(counts)[::2]])\n",
    "#  p l o t\n",
    "plt.plot(X[0],Y[0])\n",
    "\n",
    "X = torch.from_numpy(X).type(torch.FloatTensor).T\n",
    "Y = torch.from_numpy(Y).type(torch.FloatTensor).T\n",
    "X_test = torch.from_numpy(X_test).type(torch.FloatTensor).T\n",
    "Y_test = torch.from_numpy(Y_test).type(torch.FloatTensor).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "TEXT NEEDED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5x3Q6Y-mHF3S"
   },
   "outputs": [],
   "source": [
    "class DenseRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        # let's inherit everything from Module\n",
    "        super(DenseRegression,self).__init__()\n",
    "        # our network will have 3 layers: one input, one hidden, and one output\n",
    "        self.fc1 = nn.Linear(1,256)\n",
    "        self.fc2 = nn.Linear(256,1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # first layer output\n",
    "        x = self.fc1(x)\n",
    "        # using leaky ReLU activation function\n",
    "        x = F.leaky_relu(x)\n",
    "        # getting the output\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xWT2S_H9GRFC"
   },
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MAdiTbMwGTCV"
   },
   "outputs": [],
   "source": [
    "# init the model       \n",
    "model = DenseRegression()\n",
    "# define the loss function as mean squared error this time\n",
    "criterion = nn.MSELoss()\n",
    "# define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1.3)\n",
    "\n",
    "# number of training epochs\n",
    "epochs = 500\n",
    "# let's keep track of losses\n",
    "losses = []\n",
    "for i in range(epochs):\n",
    "    # predict the model output for input\n",
    "    Y_pred = model.forward(X)\n",
    "    # calculate the loss\n",
    "    loss = criterion(Y_pred,Y)\n",
    "    losses.append(loss.item())\n",
    "    # clear previous gradients\n",
    "    optimizer.zero_grad()\n",
    "    # compute gradient\n",
    "    loss.backward()\n",
    "    # update weights\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "5pb5xPHlGyse",
    "outputId": "aa88ebeb-811f-4da7-d47a-bf60ca61ca03"
   },
   "outputs": [],
   "source": [
    "Y_pred = model.forward(X).detach().numpy()\n",
    "# p l o t\n",
    "plt.plot(X,Y)\n",
    "plt.plot(X,Y_pred)\n",
    "# how does the test data do?\n",
    "Y_pred_test = model.forward(X_test).detach().numpy()\n",
    "plt.plot(X_test,Y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-0Tx8IN0O4vD"
   },
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:purple\">>>>QUESTION</span>\n",
    "\n",
    "\n",
    "Question text needed...\n",
    "\n",
    "\n",
    "<br>\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "deep_learning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
