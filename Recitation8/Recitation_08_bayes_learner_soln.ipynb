{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "<hr style=\"height: 1px;\">\n",
    "<i>This code was authored by the 8.S50x Course Team, Copyright 2021 MIT All Rights Reserved.</i>\n",
    "<hr style=\"height: 1px;\">\n",
    "<br>\n",
    "\n",
    "# RECITATION 8a: Bayesian statistics\n",
    "\n",
    "<br>\n",
    "<!--end-block--> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## 8a.0 Overview of Learning Objectives\n",
    "\n",
    "In this recitation we will explore the following objectives:\n",
    "\n",
    "- fill in information\n",
    "\n",
    "<br>\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## 8a.1 Coin Toss Example\n",
    "\n",
    "Let's calculate some probability distributions for the weighting on a coin after tossing it a bunch of times.\n",
    "\n",
    "In the case where we assume a uniform prior for $p$, the probability of tossing heads, we get the following for our posterior:\n",
    "\\begin{equation} P(p\\mid D) \\propto P(p)\\cdot P(D\\mid p) = \\frac{N!}{m!(N-m)!}(1-p)^{N-m}p^m \\end{equation}\n",
    "where we've tossed the coin $N$ times and gotten heads $m$ times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "Let's define a function to calculate this for different values of $N$ and $m$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import comb\n",
    "from scipy.signal import peak_widths\n",
    "\n",
    "def with_uniform_prior(p,N,m):\n",
    "    return comb(N,m)*np.power(p,m)*np.power(1-p,N-m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:#BA2220\">>>>EXERCISE</span>\n",
    "\n",
    "\n",
    "What does this look like for $N=20$ and $m=15$?\n",
    "\n",
    "<!--end-block-->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20\n",
    "m = 15\n",
    "p = np.linspace(0,1,1000)\n",
    "posterior = with_uniform_prior(p,N,m)     # calculating P(p|D)\n",
    "plt.axvline(0.75,c='k')              # plotting the p=0.75 line\n",
    "plt.plot(p,posterior)\n",
    "plt.show()\n",
    "\n",
    "best_p = p[np.argmax(posterior)]     # getting the value of p where P(p|D) is maximized\n",
    "print('Best p: ', round(best_p,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:#BA2220\">>>>EXERCISE</span>\n",
    "\n",
    "\n",
    "What if we tossed the coin 100 times and kept the proportion of heads the same? So $N=100$ and $m=75$?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "m = 75\n",
    "posterior = with_uniform_prior(p,N,m)     # calculating P(p|D)\n",
    "plt.axvline(0.75,c='k')              # plotting the p=0.75 line\n",
    "plt.plot(p,posterior)\n",
    "plt.show()\n",
    "\n",
    "best_p = p[np.argmax(posterior)]     # getting the value of p where P(p|D) is maximized\n",
    "print('Best p: ', round(best_p,3))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:#BA2220\">>>>EXERCISE</span>\n",
    "\n",
    "\n",
    "And if we had tossed it way fewer times? $N=4$ and $m=3$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 4\n",
    "m = 3\n",
    "posterior = with_uniform_prior(p,N,m)     # calculating P(p|D)\n",
    "plt.axvline(0.75,c='k')              # plotting the p=0.75 line\n",
    "plt.plot(p,posterior)\n",
    "plt.show()\n",
    "\n",
    "best_p = p[np.argmax(posterior)]     # getting the value of p where P(p|D) is maximized\n",
    "print('Best p: ', round(best_p,3)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "\n",
    "So you can see that the number of data points influences the width of $P(p|D)$, giving us a straightforward way of calculating an uncertainty on the value of $p$ -- which stays the same in all cases. Bayesian statistics gives us a clear recipe to analyze all three of these situations.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## 8a.2 Another prior\n",
    "Let's assume that unfair coins are super rare, and define a different prior for this case. With 99% probability, the coin is nearly perfectly weighted. We'll model this as a Gaussian with mean 0.5 and $\\sigma=0.01$. With 1% chance, it is an unfair coin -- in this case we have no idea what $p$ is so we'll use a uniform distribution.\n",
    "\\begin{equation} P(p) = 0.99\\cdot \\frac{1}{0.01\\sqrt{2\\pi}}\\exp\\left(-\\frac{1}{2}\\cdot\\frac{(p-0.5)^2}{\\sigma^2}\\right)+0.01\\cdot1 \\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:green\">>>>RUN</span>\n",
    "\n",
    "Run the cell below to define the funtionc <code>with_new_prior()</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def with_new_prior(p,N,m):\n",
    "    prior = 0.99 / (0.01 * np.sqrt(2*np.pi)) * np.exp(-(p-0.5)**2/(2*0.01**2))+0.01\n",
    "    return prior*with_uniform_prior(p,N,m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:#BA2220\">>>>EXERCISE</span>\n",
    "\n",
    "\n",
    "As above, what does this look like for ùëÅ=20 and ùëö=15?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20\n",
    "m = 15\n",
    "posterior = with_new_prior(p,N,m)     # calculating P(p|D)\n",
    "plt.plot(p,posterior)\n",
    "plt.show()\n",
    "\n",
    "best_p = p[np.argmax(posterior)]     # getting the value of p where P(p|D) is maximized\n",
    "print('Best p: ', round(best_p,3)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:#BA2220\">>>>EXERCISE</span>\n",
    "\n",
    "This prior really changes the results! In the $N=20$ and $m=15$ cases, this looks a lot like a fair coin. What if we add more events? Try ùëÅ=80 and ùëö=60?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 80\n",
    "m = 60\n",
    "posterior = with_new_prior(p,N,m)     # calculating P(p|D)\n",
    "plt.plot(p,posterior)\n",
    "best_p = p[np.argmax(posterior)]     # getting the value of p where P(p|D) is maximized\n",
    "plt.axvline(best_p,c='k')\n",
    "plt.show()\n",
    "\n",
    "print('Best p: ', round(best_p,3)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:#BA2220\">>>>EXERCISE</span>\n",
    "\n",
    "\n",
    "Try ùëÅ=200 and ùëö=150?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 200\n",
    "m = 150\n",
    "posterior = with_new_prior(p,N,m)     # calculating P(p|D)\n",
    "plt.plot(p,posterior)\n",
    "best_p = p[np.argmax(posterior)]     # getting the value of p where P(p|D) is maximized\n",
    "plt.axvline(best_p,c='k')\n",
    "plt.show()\n",
    "\n",
    "print('Best p: ', round(best_p,3)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "So you can see a clear dependance on the choice of prior!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:purple\">>>>QUESTION</span>\n",
    "\n",
    "\n",
    "Question text needed...\n",
    "\n",
    "\n",
    "<br>\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
