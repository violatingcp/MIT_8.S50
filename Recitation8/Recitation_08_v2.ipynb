{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "<hr style=\"height: 1px;\">\n",
    "<i>This code was authored by the 8.S50x Course Team, Copyright 2021 MIT All Rights Reserved.</i>\n",
    "<hr style=\"height: 1px;\">\n",
    "<br>\n",
    "\n",
    "# Recitation 8: Bayesian and Frequentist Statistics\n",
    "\n",
    "<br>\n",
    "<!--end-block--> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "<hr style=\"height: 1px;\">\n",
    "## 8.0 Overview of Learning Objectives:\n",
    "\n",
    "In this recitation we will explore the following objectives:\n",
    "\n",
    "-Understand the basis for Bayes' theorem\n",
    "\n",
    "-Discuss how it fits into more general Bayesian statistics and its difference from frequentists' perspective\n",
    "\n",
    "-Look at examples of applying Bayes' theorem\n",
    "\n",
    "<br>\n",
    "<!--end-block-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## 8.0 Bayes' Theorem\n",
    "\n",
    "Bayes' Theorem is defined as the following and contains a few working parts to discuss:<br><br>\n",
    "\\begin{equation}\n",
    "P(A|B)=\\frac{P(A) \\cdot P(B|A)}{P(B)}\n",
    "\\end{equation}\n",
    "\n",
    "* $P(A|B)$, the probability of $A$ happening if $B$ is true, known as the \"posterior\" probability\n",
    "* $P(A)$, the probability of $B$ happening, known as the \"prior\" probability of $A$\n",
    "* $P(B|A)$, the probability of $B$ happening if $A$ is true, also known as the likelihood\n",
    "* $P(B)$, probability of whether $B$ would have happened regardless of $A$\n",
    "\n",
    "<br><br>\n",
    "Usually $P(B)$ is just treated as a normalizing factor, and since we need other hypothesis for comparison in order to measure $P(B)$, this is often ommited from the expression and we often just quote:\n",
    "\\begin{equation*}\n",
    "P(A|B)\\propto P(A)\\cdot P(B|A)\n",
    "\\end{equation*}\n",
    "\n",
    "Often outside of the more general events $A$ and $B$ in this course we will more often use\n",
    "\\begin{equation*}\n",
    "P(M|D)\\propto P(M)\\cdot P(D|M)\n",
    "\\end{equation*}\n",
    "Where $D$ is the data in question and $M$ is the model we are attempting to apply to the observed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <!--start-block-->\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## 8.1 Frequentist vs. Bayesian Picture\n",
    "Let's take an example from flipping a coin. We don't know if it's a fair coin (equal probability for heads or tails) or an unfair coin (unequal probability for heads vs tails). We'll refer to the probability for heads and tails respectively here as $P(H)$ and $P(T)$.<br><br>\n",
    "\n",
    "After flipping the coin 20 times we obtain heads 15 times.\n",
    "\n",
    "### Frequentist Picture\n",
    "\n",
    "For the frequentist, they will analyze the data by seeing that we have $P(H)=3/4$, therefore we must have an unfair coin!\n",
    "\n",
    "### Bayesian Picture\n",
    "\n",
    "For the Bayesian statistician, they would be a little uncomfortable with this conclusion. Instead of stating that our parameter $p=P(H)$ is some fixed quantity that should be clear from our data, the Bayesian states that $p(H)$ is a random variable. <br><br>\n",
    "In this case our parameter $p=P(H)$ corresponds to our prior $P(M)$. Since the Bayesian picture states that $p$ should be some random variable, let us assume a uniform prior $P(p)=P(M)=1$. Using Bayes' equation we now have:<br><br>\n",
    "\\begin{gather*}\n",
    "P(p|D)\\propto P(p)\\cdot P(D|p)= \\frac{N!}{m!(N-m)!}(1-p)^{N-m} p^{m}\n",
    "\\end{gather*}<br><br>\n",
    "This follows from the fact that $P(D|p)$, the probability that we get heads $m$ out of $N$ times based on the probability $p$, should follow a binomial distribution. We can use this to plot out the probability distribution for $p$ for given values of $N$ and $m$ using python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import comb\n",
    "from scipy.signal import peak_widths\n",
    "\n",
    "def with_uniform_prior(p,N,m):\n",
    "    return comb(N,m)*np.power(p,m)*np.power(1-p,N-m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<!--start-block-->\n",
    "#### <span style=\"color:#BA2220\">>>>EXERCISE</span> \n",
    "\n",
    "Using the function above, plot out the probability distribution of $p$ for $N=20,$ $m=15$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:#BA2220\">>>>EXERCISE</span> \n",
    "\n",
    "Using your script from the first exercise, plot the probability distributions for $p$ for the values:\n",
    "* $N$=100, $m$=75\n",
    "* $N$=4, $m$=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "<hr style=\"height: 1px;\"> <br>\n",
    "\n",
    "## 8.2 A New Prior\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's change our prior assumptions and retackle this same coin flipping situation.<br><br>\n",
    "Let's instead approach this with the assumption that it's very rare for a coin to be unfair and that we're 99% sure we're dealing with a normal coin. We can model this as a Gaussian with a mean at $p=0.5$ and $\\sigma=0.01$.<br><br>\n",
    "\n",
    "We now change our prior a bit to represent our new assumptions:\n",
    "\\begin{gather*}\n",
    "P(p)=0.99\\cdot \\frac{1}{\\sqrt{2\\pi}\\cdot 0.01}\\exp\\left(-\\frac{1}{2}\\frac{(p-0.5)^2}{(0.01)^2}\\right)+0.01\n",
    "\\end{gather*}\n",
    "\n",
    "As before we can plot out how this affects our distribution for $p$ with the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def with_new_prior(p,N,m):\n",
    "    prior = 0.99 / (0.01 * np.sqrt(2*np.pi)) * np.exp(-(p-0.5)**2/(2*0.01**2))+0.01\n",
    "    return prior*with_uniform_prior(p,N,m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "#### <span style=\"color:#BA2220\">>>>EXERCISE</span> \n",
    "\n",
    "Using the new prior, redo the distributions for $p$ for the following values of $N$ and $m$:\n",
    "* $N=20$, $m=15$\n",
    "* $N=3$, $m=3$\n",
    "* $N=100$, $m=75$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--start-block-->\n",
    "<hr style=\"height: 1px;\"> <br>\n",
    "\n",
    "## 8.3 Conclusions\n",
    "\n",
    "As we have seen, the conclusions from Bayesian perspectives all depend on your choice of prior when approaching the situation, i.e. whether we assumed that the coin was likely unfair or not.<br><br>\n",
    "\n",
    "This isn't necessarily a bad thing, it allows us to build on our observations by applying things we know or suspect. There is the counter to this as we observed that if our prior significantly changes our answer then our data isn't very constrained by our model. <br><br>\n",
    "\n",
    "Our exploration of the difference between the frequentist and Bayesian analysis should not leave you with the idea that one is much better or accurate than the other, both are powerful tools for data analysis that have different cases for optimal use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
